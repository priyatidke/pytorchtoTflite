{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rapid_submit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3AgGZX+HOZylQY13Iv5cO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyatidke/pytorchtoTflite/blob/main/Rapid_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvoaaOipIqst"
      },
      "source": [
        "**Machine Learning / Deep Learning Engineer Evaluation Task**\n",
        "\n",
        "**Goal:**\n",
        "\n",
        "The goal of this task to be able to run a pose estimation model in C++ using Tensorflow Lite C++ API.\n",
        "\n",
        "**Task 1:** Convert the Pytorch model from pose_hrnet_w32_256x256.pth to TensorFlow Lite model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwWo6OoVurbn",
        "outputId": "583a973d-8a6f-450a-b220-0dacf8b27450"
      },
      "source": [
        "#To check Tensorflow version\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdIGMvtvt0q4",
        "outputId": "46f328b5-ac2d-4eb1-ab0b-b0f6cb1b1ea1"
      },
      "source": [
        "#GPU device\n",
        "import tensorflow as tf\n",
        "\n",
        "devices = tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
        "devices"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJsCWd_vRH7w",
        "outputId": "f4f6e45d-930d-41bf-d50a-1c8bdb4a074d"
      },
      "source": [
        "#install onnx_tf \n",
        "!pip install onnx_tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx_tf in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: onnx>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (1.9.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (0.12.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx_tf) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx_tf) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx_tf) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx_tf) (1.19.5)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx_tf) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.8.0->onnx_tf) (56.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZwVdbjsJ_gv",
        "outputId": "5f7e2461-c00f-46df-d2c8-fc04a14ac4ac"
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAkgPLlZPYYc",
        "outputId": "60ec458f-6e19-4693-b2a2-10e25dfbc505"
      },
      "source": [
        "# Accessing My Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nObYEviUQJ3R"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irwB_xN-KU3c"
      },
      "source": [
        "**Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCT_6-qoQVeM"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import onnx\n",
        "from onnx import backend\n",
        "from onnx_tf.backend import prepare\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMr6ySO0QV8w"
      },
      "source": [
        "#set path for file\n",
        "PATH = \"drive/My Drive/POSE/pose_hrnet_w32_256x256.pth\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcH6kPBRbxah"
      },
      "source": [
        "**Define SuperResolutionNet model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCxOHzOCQhKA"
      },
      "source": [
        "#Base model\n",
        "#SuperResolutionNet model\n",
        "\n",
        "class SuperResolutionNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, inplace=False):\n",
        "        super(SuperResolutionNet, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.conv1 = nn.Conv2d(3, 64, (3, 3), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        #self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR8kNoGBQsHw",
        "outputId": "4b551ab3-b59c-4d3a-a398-888f4e956347"
      },
      "source": [
        "# Create the super-resolution model by using the above model definition.\n",
        "model = SuperResolutionNet(upscale_factor=3)\n",
        "\n",
        "# Initialize model with the pretrained weights\n",
        "model.load_state_dict(torch.load(PATH), strict=False)\n",
        "\n",
        "# set the model to inference mode\n",
        "model.eval()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuperResolutionNet(\n",
              "  (relu): ReLU()\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECrFzou9QxY2"
      },
      "source": [
        "#Generate and pass random input so the Pytorch exporter can trace the model and save it to an ONNX file\n",
        "\n",
        "dummy_input = Variable(torch.randn(1, 3, 224, 224))\n",
        "torch.onnx.export(model, dummy_input, \"drive/My Drive/POSE/hrnet_new.onnx\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUCacDWQ55E"
      },
      "source": [
        "#Load the ONNX file \n",
        "onnx_model = onnx.load('drive/My Drive/POSE/hrnet_new.onnx')\n",
        "\n",
        "#import ONNX model to Tensorflow\n",
        "tf_rep = prepare(onnx_model) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llYW0UpURTCk",
        "outputId": "7efd2035-a1ff-4d15-8db4-6e9f3169ceca"
      },
      "source": [
        "#inputs node to the model\n",
        "print(\"inputs:\", tf_rep.inputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: ['input.1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fw1KizNRawy",
        "outputId": "8b6ea40a-1004-4c97-c39c-0b4c279edfec"
      },
      "source": [
        "#outputs node from the model\n",
        "print(\"outputs:\", tf_rep.outputs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outputs: ['20']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoXBM8BJRddB",
        "outputId": "125aeb19-54f3-459a-9ee8-393d9e28c9b4"
      },
      "source": [
        "#All nodes in the model\n",
        "print(\"tensor_dict\")\n",
        "print(tf_rep.tensor_dict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor_dict\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY0PdKDvRhqZ",
        "outputId": "35689f5d-108d-4a3a-81db-aa927e00d9e4"
      },
      "source": [
        "# exporting to TensorFlow graphs\n",
        "tf_rep.export_graph('drive/My Drive/POSE/hrnet_new.pb')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/POSE/hrnet_new.pb/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/POSE/hrnet_new.pb/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6cElZCLO9hQ"
      },
      "source": [
        "**TensorFlow Model to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-SllporRz34"
      },
      "source": [
        "#load TensorFlow model from saved_model\n",
        "loaded = tf.saved_model.load('drive/My Drive/POSE/hrnet_new.pb')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkh02x-FSZLl"
      },
      "source": [
        "#Concrete Function\n",
        "concrete_func = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "\n",
        "concrete_func.inputs[0].set_shape([1, 3, 224, 224])\n",
        "\n",
        "#To load the concrete function into the TFLiteConverter\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPbcq1DXSwW7"
      },
      "source": [
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23W9P-zYSy8C"
      },
      "source": [
        "#converte TensorFlow Lite model\n",
        "tf_lite_model = converter.convert()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKQFWX3AS1KB",
        "outputId": "5c553cbc-c064-4f5b-b990-d678afefa254"
      },
      "source": [
        "#Store the Model\n",
        "open('drive/My Drive/POSE/hrnet_new.tflite', 'wb').write(tf_lite_model)\n",
        "\n",
        "print(\"Converted to tensorflow lite succesfully.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted to tensorflow lite succesfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYLb27PrRAqq"
      },
      "source": [
        "**Inference with TFLite model**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3_FeeSIS-vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ae2b31-f0f9-420b-e584-7a57a724557f"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path='drive/My Drive/POSE/hrnet_new.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "print(\"input_details\",input_details)\n",
        "output_details = interpreter.get_output_details()  \n",
        "print(\"output_details\", output_details)      \n",
        "input_shape = input_details[0]['shape']\n",
        "print(\"input_shape\", input_shape)      \n",
        "\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "print(\"input_data\", input_data)      \n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_details [{'name': 'input_1', 'index': 0, 'shape': array([  1,   3, 224, 224], dtype=int32), 'shape_signature': array([  1,   3, 224, 224], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "output_details [{'name': 'Identity', 'index': 28, 'shape': array([  1,   1, 678, 678], dtype=int32), 'shape_signature': array([  1,   1, 678, 678], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "input_shape [  1   3 224 224]\n",
            "input_data [[[[0.7076335  0.5023663  0.5260045  ... 0.8175962  0.19163184\n",
            "    0.4107162 ]\n",
            "   [0.34354818 0.76715    0.8471102  ... 0.94694155 0.94958943\n",
            "    0.85409456]\n",
            "   [0.46885368 0.12112184 0.16566078 ... 0.68074465 0.7744152\n",
            "    0.67900735]\n",
            "   ...\n",
            "   [0.7261805  0.65203255 0.02939074 ... 0.6707684  0.7369256\n",
            "    0.0892553 ]\n",
            "   [0.24418044 0.9314134  0.05062401 ... 0.10698013 0.64083356\n",
            "    0.72926444]\n",
            "   [0.2997018  0.38237864 0.6813385  ... 0.04877192 0.8979996\n",
            "    0.6791751 ]]\n",
            "\n",
            "  [[0.94001824 0.7208592  0.09844073 ... 0.32284757 0.50598836\n",
            "    0.2790774 ]\n",
            "   [0.78470695 0.36403406 0.47445107 ... 0.7635727  0.8019782\n",
            "    0.01258905]\n",
            "   [0.8335474  0.27474865 0.9915964  ... 0.9744134  0.793028\n",
            "    0.33052173]\n",
            "   ...\n",
            "   [0.43478927 0.8800762  0.6081753  ... 0.42670995 0.5092017\n",
            "    0.13339299]\n",
            "   [0.42478523 0.02043479 0.6785239  ... 0.75588155 0.4578458\n",
            "    0.68544364]\n",
            "   [0.6636911  0.7198594  0.7215846  ... 0.9897874  0.39081773\n",
            "    0.48893985]]\n",
            "\n",
            "  [[0.63468975 0.78722715 0.72482634 ... 0.66927046 0.17868796\n",
            "    0.703944  ]\n",
            "   [0.6080511  0.771544   0.6293476  ... 0.15409605 0.04592046\n",
            "    0.43300328]\n",
            "   [0.8083186  0.22635616 0.3160323  ... 0.26157388 0.47826636\n",
            "    0.01727927]\n",
            "   ...\n",
            "   [0.8241901  0.91102916 0.76516134 ... 0.25015485 0.7675932\n",
            "    0.45241877]\n",
            "   [0.4517734  0.7675741  0.08655118 ... 0.6340362  0.15701237\n",
            "    0.5554504 ]\n",
            "   [0.9653682  0.67423505 0.7979335  ... 0.4506167  0.3902037\n",
            "    0.685309  ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8vG-FJto6kQ"
      },
      "source": [
        "#interpreter.invoke()\n",
        "\n",
        "#y = interpreter.get_tensor(output_details[0]['index'])    \n",
        "#feature =  interpreter.get_tensor(output_details[1]['index'])"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}